## ME 343 Homepage

Welcome to this class. We hope you will enjoy it!

This is the first time this class is offered by the Mechanical Engineering Department so we will be experimenting with the content a bit. Here is the tentative content. We will make some adjustments as we go depending on interest and time left:

- Gaussian process regression
- Support vector machine for classification; kernel machines
- Deep learning
- Recurrent Neural Network
- Generative Adversarial Networks (GAN)
- Physics-informed learning machines (a new method specific to ME!)
- Reinforcement learning
- Markov decision processes, Bellman equation, Monte-Carlo tree search, and dynamic programming
- Temporal-difference learning (if time allows)

The material for this class is hosted on github. It can be downloaded from the main repository page
 [https://github.com/stanford-me343/stanford-me343.github.io](https://github.com/stanford-me343/stanford-me343.github.io)

 If you click on the green button "Clone or download" you can download all the files as a zip archive.

### Office hours

- Tuesday: 7 PM to 8 PM (Hojat)
- Wednesday: 10 AM to 11 AM (Ziyi/Hojat)
- Thursday: 10 AM to 11 AM (Ziyi)
- Friday: 9 AM to 11 AM (Prof. Darve)

Office hours with TAs are held in the Huang basement. Prof. Darve's office hours are in building 520, room 125.

### Course material and links

- [Final project](project/project.pdf)
- [Homework assignment folder](hwk.md)
- [Piazza forum](https://piazza.com/class/jqffwoswj8k50a)
- [Gradescope](https://www.gradescope.com/); used to submit your assignments, see your grades, and request regrades for assignments.
- [Mailing list](https://mailman.stanford.edu/mailman/listinfo/me343-winter1819); the instructors use this mailing list to send important messages; **please check that you are registered.**
- [Syllabus](syllabus.md)
- [Computer code](code.md)
- Final project instructions (to be posted later)
- Interactive poll and survey link:
[https://pollev.com/ericdarve886](https://pollev.com/ericdarve886)

### Contact information

- Main instructor: Eric Darve, [darve@stanford.edu](mailto:darve@stanford.edu), office 520-125
- Lecturer: Hojat Ghorbanidehno, [hojjatgh@stanford.edu](mailto:hojjatgh@stanford.edu)
- TA: Ziyi Yang, [ziyi.yang@stanford.edu](mailto:ziyi.yang@stanford.edu)

### Reading material

### GAN

- [Generative Adversarial Nets](https://arxiv.org/pdf/1406.2661.pdf) by I.J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, Y. Bengio
- [Conditional Generative Adversarial Nets](https://arxiv.org/pdf/1411.1784.pdf) by M. Mirza, S. Osindero

### Deep learning

- LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. ["Deep learning."](https://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf) Nature 521.7553 (2015): 436.
- [Deep learning](http://www.deeplearningbook.org/) by I. Goodfellow, Y. Bengio, and A. Courville
- [Deep learning summer school, Montreal 2015](http://videolectures.net/deeplearning2015_montreal/), with many video presentations and tutorials
- [Deep learning for perception](https://computing.ece.vt.edu/~f15ece6504/), course from Virginia Tech
- [Deep learning methods and applications](https://drive.google.com/file/d/0B51wXUnyPM2ybVAwRXBrdFVPSk0/view), online book by L. Deng and D. Yu
- [Neural networks and deep learning](http://neuralnetworksanddeeplearning.com/index.html), online book by M. Nielsen
- ["Optimization methods for large-scale machine learning,"](https://arxiv.org/pdf/1606.04838.pdf) by L. Bottou. F.E. Curtis, and J. Nocedal. This paper discusses among other things the stochastic gradient method.

### SVM

- [A tutorial on support vector regression](https://link.springer.com/article/10.1023/B:STCO.0000035301.49549.88) by Smola and Scholkopf
- [A tutorial on support vector machines for pattern
recognition](https://link.springer.com/article/10.1023/A:1009715923555) by Burges. They have a very interesting mechanical analogy in terms of force and torque for the separating hyperplane.

### GPR

- [Gaussian processes for machine learning](http://www.gaussianprocess.org/gpml/) by Carl Edward Rasmussen and Christopher K. I. Williams, The MIT Press, 2006. ISBN 0-262-18253-X. This is a reference textbook on Gaussian Processes. Very extensive. Everything you ever wanted to know about GPR.
- Short review paper; [Gaussian processes for regression](http://papers.nips.cc/paper/1048-gaussian-processes-for-regression.pdf) by Williams and Rasmussen
- Intermediate review paper; [Introduction to gaussian processes](https://www.ics.uci.edu/~welling/teaching/KernelsICS273B/gpB.pdf) by Mackay
- Intermediate review paper; [Prediction with gaussian processes from linear regression to linear prediction and beyond](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.84.1226&rep=rep1&type=pdf) by Williams
- Longer review paper with an introduction to Gaussian processes on a fairly elementary level; [Gaussian processes for machine learning](https://infoscience.epfl.ch/record/161301/files/bayesgp-tut.pdf) by Seeger
